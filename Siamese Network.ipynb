{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ad22779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Conv2D, Lambda, Dense, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98d8ad48-f700-4746-9e52-58d02442ff8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3d2b7e-9306-4781-93e7-e02c034387ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8c2a1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, target_size=(128,128)):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img,target_size)\n",
    "    img = img/255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371bb88e-e65e-4210-8235-2d3ca091de64",
   "metadata": {},
   "source": [
    "## Creating image triplets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed6e315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_triplets(whale_folder_path, num_pairs_per_id = 10, img_size=(128,128)):\n",
    "    whale_ids = os.listdir(whale_folder_path)\n",
    "#     anchor = []\n",
    "#     postive_pairs = []\n",
    "#     negative_pairs = []\n",
    "    triplets = []\n",
    "    \n",
    "    #m7tgeen n3ml el anchor wl pos wl neg mn different folder \n",
    "    \n",
    "    for whale_id in whale_ids:\n",
    "        whale_images_path = os.path.join(whale_folder_path, whale_id)\n",
    "        whale_images = [os.path.join(whale_images_path, img) for img in os.listdir(whale_images_path) if img.endswith('.jpg')]\n",
    "        number_of_whales = len(whale_images)\n",
    "        \n",
    "        for i in range(num_pairs_per_id):\n",
    "            anchor, positive = random.sample(whale_images,2)\n",
    "            negative_whale_id = random.choice([id for id in whale_ids if id != whale_id])\n",
    "            negative_whale_images_path = os.path.join(whale_folder_path,negative_whale_id)\n",
    "            negative = random.choice([os.path.join(negative_whale_images_path, img) for img in os.listdir(negative_whale_images_path) if img.endswith('.jpg')])\n",
    "            \n",
    "            #ekhtarna random sets n append ll triples\n",
    "            \n",
    "            triplets.append((anchor,positive,negative))\n",
    "            random.shuffle(triplets)\n",
    "    print(len(triplets))\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb77dab-431f-4c35-b42f-d763b503de74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "612a00b6-ab6a-4f26-ab35-f2e9ca27fe12",
   "metadata": {},
   "source": [
    "## Preprocessing the triplets images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e551793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_triplets(triplets, img_size=(128, 128)):\n",
    "    anchors, positives, negatives = [], [], []\n",
    "\n",
    "    for anchor_path, positive_path, negative_path in triplets:\n",
    "        anchor = preprocess_image(anchor_path, img_size)\n",
    "        positive = preprocess_image(positive_path, img_size)\n",
    "        negative = preprocess_image(negative_path, img_size)\n",
    "\n",
    "        anchors.append(anchor)\n",
    "        positives.append(positive)\n",
    "        negatives.append(negative)\n",
    "\n",
    "    return np.array(anchors), np.array(positives), np.array(negatives)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a244d5-77c7-4e59-9440-31509e609c63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8161a683-d815-4ba0-9cc4-c385eae88b1a",
   "metadata": {},
   "source": [
    "## Create Pairs with Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b45464de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairs(anchors, positives, negatives):\n",
    "    pairs = []\n",
    "    labels = []\n",
    "\n",
    "    for i in range(len(anchors)):\n",
    "        pairs += [[anchors[i], positives[i]]]\n",
    "        labels += [1.0]  # Cast label as float\n",
    "\n",
    "    for i in range(len(anchors)):\n",
    "        pairs += [[anchors[i], negatives[i]]]\n",
    "        labels += [0.0]  # Cast label as float\n",
    "\n",
    "    return np.array(pairs), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "301755b2-2abf-4661-ba8f-8b0da1853588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_10 (InputLayer)          [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " model_2 (Functional)           (None, 4096)         17988928    ['input_9[0][0]',                \n",
      "                                                                  'input_10[0][0]']               \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 4096)         0           ['model_2[0][0]',                \n",
      "                                                                  'model_2[1][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            4097        ['lambda_1[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 17,993,025\n",
      "Trainable params: 17,993,025\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def create_base_network(input_shape):\n",
    "    input = Input(shape=input_shape)\n",
    "    x = Conv2D(64, (10,10), activation='relu')(input)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = Conv2D(128, (7,7), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = Conv2D(128, (4,4), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = Conv2D(256, (4,4), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(4096, activation='sigmoid')(x)\n",
    "    return Model(input, x)\n",
    "\n",
    "input_shape = (128, 128, 3)\n",
    "base_network = create_base_network(input_shape)\n",
    "\n",
    "input_a = Input(shape=input_shape)\n",
    "input_b = Input(shape=input_shape)\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "distance = Lambda(lambda tensors: K.abs(tensors[0] - tensors[1]))([processed_a, processed_b])\n",
    "output = Dense(1, activation='sigmoid')(distance)\n",
    "\n",
    "model = Model([input_a, input_b], output)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(0.0001), metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da383a78-3435-4836-bbcb-3bf093fd8cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "Epoch 1/15\n",
      " 11/200 [>.............................] - ETA: 6s - loss: 0.6929 - accuracy: 0.5091"
     ]
    }
   ],
   "source": [
    "test = r\"C:\\Users\\islam\\Downloads\\Dataset\\Dataset\\few-shot-learning\\train\\whale\"\n",
    "triplets = create_image_triplets(test) \n",
    "anchors, positives, negatives = preprocess_triplets(triplets)\n",
    "pairs, labels = create_pairs(anchors, positives, negatives)\n",
    "\n",
    "# Ensure pairs is a list of two numpy arrays\n",
    "pairs = [np.array([pair[0] for pair in pairs]), np.array([pair[1] for pair in pairs])]\n",
    "\n",
    "# Ensure labels are of the correct shape\n",
    "labels = np.array(labels).reshape(-1, 1)\n",
    "\n",
    "# Train the model\n",
    "model.fit(pairs, labels, batch_size=5, epochs=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cfc1249-1be9-46ba-9e16-3ad23016c4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_reference_images(train_folder):\n",
    "    reference_images = {}\n",
    "    whale_ids = os.listdir(train_folder)\n",
    "    print(\"whale ids are\",whale_ids)\n",
    "\n",
    "    for whale_id in whale_ids:\n",
    "        whale_folder = os.path.join(train_folder, whale_id)\n",
    "        for img_file in os.listdir(whale_folder):\n",
    "            if img_file.endswith('.jpg'):\n",
    "                img_path = os.path.join(whale_folder, img_file)\n",
    "                reference_images[whale_id] = preprocess_image(img_path)\n",
    "                break  # Select the first image as reference and move to next ID\n",
    "\n",
    "    return reference_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68f81c51-a10b-48a5-a39a-f9d124f7f793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_validation_images(validation_folder):\n",
    "    validation_images = []\n",
    "    image_paths = []\n",
    "\n",
    "    for img_file in os.listdir(validation_folder):\n",
    "        if img_file.endswith('.jpg'):\n",
    "            img_path = os.path.join(validation_folder, img_file)\n",
    "            img = preprocess_image(img_path)\n",
    "            validation_images.append((img, img_path))\n",
    "\n",
    "    return validation_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "317a19ed-8689-4e1b-9744-c2ca07584e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whale ids are ['51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67']\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "similarity is  [[0.09120983]] whale id is 51\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "similarity is  [[0.00363087]] whale id is 52\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "similarity is  [[0.00025228]] whale id is 53\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "similarity is  [[0.4326236]] whale id is 54\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "similarity is  [[0.55875623]] whale id is 55\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "similarity is  [[0.27983573]] whale id is 56\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "similarity is  [[0.08193381]] whale id is 57\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "similarity is  [[0.44255915]] whale id is 58\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "similarity is  [[0.10400219]] whale id is 59\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "similarity is  [[0.9479115]] whale id is 60\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "similarity is  [[9.020062e-05]] whale id is 61\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "similarity is  [[0.3919568]] whale id is 62\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "similarity is  [[0.00378119]] whale id is 63\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "similarity is  [[0.16080444]] whale id is 64\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "similarity is  [[0.8202052]] whale id is 65\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "similarity is  [[0.5125084]] whale id is 66\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "similarity is  [[0.84913665]] whale id is 67\n",
      "Image C:\\Users\\islam\\Downloads\\New folder (2)\\v_291.jpg is predicted to be Whale ID: 60\n"
     ]
    }
   ],
   "source": [
    "def predict_whale_id(model, test_image, reference_images):\n",
    "    max_similarity = 0\n",
    "    predicted_id = None\n",
    "\n",
    "    for whale_id, ref_image in reference_images.items():\n",
    "        similarity = model.predict([np.expand_dims(test_image, axis=0), np.expand_dims(ref_image, axis=0)])\n",
    "        print(\"similarity is \" , similarity, \"whale id is\",whale_id)\n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            predicted_id = whale_id\n",
    "    return predicted_id\n",
    "\n",
    "# Assuming model is your trained Siamese model\n",
    "train_folder = r\"C:\\Users\\islam\\Downloads\\Dataset\\Dataset\\few-shot-learning\\val\\whale\"\n",
    "validation_folder = r\"C:\\Users\\islam\\Downloads\\New folder (2)\"\n",
    "\n",
    "reference_images = select_reference_images(train_folder)\n",
    "validation_images = load_validation_images(validation_folder)\n",
    "\n",
    "for test_image, test_image_path in validation_images:\n",
    "    predicted_id = predict_whale_id(model, test_image, reference_images)\n",
    "    print(f\"Image {test_image_path} is predicted to be Whale ID: {predicted_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f8c3d2-0162-4f31-8785-a7b1e1b8db49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
